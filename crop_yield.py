# -*- coding: utf-8 -*-
"""Crop Yield.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mQmvVCVOoncVLKz0wQt0QqFCSJuvjrS1
"""

pip install sklearn.cross_validation

pip install scipy

import pickle 
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt 
from sklearn import metrics
from sklearn.svm import SVR 
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder 
from sklearn.compose import ColumnTransformer 
from sklearn.model_selection  import train_test_split

df = pd.read_excel('/content/DATASET.xlsx')

df

df.info()

df.describe()

df.shape

df1 = df.drop(labels='yield(kg/hect)', axis = 1)

df1

df1.corr()

sns.heatmap(df1.corr(), annot = True)

labelencoder = LabelEncoder()

df1['State']= labelencoder.fit_transform(df1['State'])

df1['State'].unique()

df['State'].unique()

dict(zip(df['State'].unique(), df1['State'].unique()))

list1 = [0]*28

list1

df1

onehotencoder = OneHotEncoder()

encoded_df = pd.DataFrame(onehotencoder.fit_transform(df1[['State']]).toarray())

encoded_df

df2 = encoded_df.join(df1)

df2

df3 = df2.drop(labels = [0, 'State'], axis =1)

df3

df3.columns.tolist()

sns.pairplot(df)

sns.distplot(df['Production(tons)'])

df3

df3.dropna(inplace=True)

df3.info()

X = df3.iloc[:, :29]

X

Y = df3['Production(tons)']

Y

x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3,  random_state = 20)

x_train.shape

x_test.shape

y_train.shape

y_test.shape

lm = LinearRegression()

lm.fit(x_train, y_train)

print(lm.intercept_)

lm.coef_

x_train.columns

pd.DataFrame(lm.coef_, X.columns, columns = ["Coefficient"])

prediction = lm.predict(x_test)

plt.scatter(y_test, prediction)

sns.distplot((y_test - prediction))

metrics.mean_absolute_error(y_test, prediction)

np.sqrt(metrics.mean_squared_error(y_test, prediction))

metrics.explained_variance_score(y_test, prediction)

lm

#Save Model
filename = '/content/lrmodel.pkl'
pickle.dump(lm, open(filename, 'wb'))

#Load Model
lr_saved_model = pickle.load(open(filename, 'rb'))
lr_saved_model.score(x_test, y_test)

final_features = [np.array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
          0,    0,    0,    0,    0, 2027, 1000])]
lr_saved_model.predict(final_features)

#SVM Model
svr_model = SVR()

svr_model.fit(x_train, y_train)

print(" SVM Model Accuracy {}".format(svr_model.score(x_train, y_train)))
print(" SVM Model Accuracy {}".format(svr_model.score(x_test, y_test)))

#Save Model
filename1 = '/content/svregressormodel.pkl'
pickle.dump(svr_model, open(filename1, 'wb'))

#Load Model
svr_saved_model = pickle.load(open(filename1, 'rb'))
svr_saved_model.score(x_test, y_test)

svr_saved_model.predict(final_features)

